{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e518c659",
   "metadata": {},
   "source": [
    "### Spark SQL (HIVE metastore) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1a3ed69e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/07/22 14:57:56 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    }
   ],
   "source": [
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import Row\n",
    "\n",
    "spark = SparkSession.builder \\\n",
    "\t.appName(\"PySpark App\") \\\n",
    "\t.enableHiveSupport() \\\n",
    "\t.getOrCreate()\n",
    "spark.sparkContext.setLogLevel(\"ERROR\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "35ff0130",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "++\n",
      "||\n",
      "++\n",
      "++\n",
      "\n",
      "++\n",
      "||\n",
      "++\n",
      "++\n",
      "\n",
      "++\n",
      "||\n",
      "++\n",
      "++\n",
      "\n",
      "++\n",
      "||\n",
      "++\n",
      "++\n",
      "\n",
      "+---+\n",
      "| id|\n",
      "+---+\n",
      "|  1|\n",
      "|  2|\n",
      "|  3|\n",
      "+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "    drop table if exists testtable;\n",
    "  \"\"\").show()\n",
    "\n",
    "spark.sql(\"\"\"\n",
    "    create table if not exists testtable(\n",
    "      id integer\n",
    "    )\n",
    "    stored as parquet;\n",
    "  \"\"\").show()\n",
    "\n",
    "spark.sql(\"\"\"\n",
    "    create table if not exists testtable_rep(\n",
    "      id integer\n",
    "    )\n",
    "    stored as parquet;\n",
    "  \"\"\").show()\n",
    "\n",
    "spark.sql(\"\"\"\n",
    "    INSERT INTO testtable VALUES (1), (2), (3)\n",
    "  \"\"\").show()\n",
    "\n",
    "spark.sql(\"\"\"\n",
    "    INSERT INTO testtable_rep\n",
    "    SELECT id FROM testtable;\n",
    "  \"\"\").show()\n",
    "\n",
    "df = spark.sql(\"select * from testtable\")\n",
    "df.show()\n",
    "\n",
    "# spark.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "62b75651",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c4b051f",
   "metadata": {},
   "source": [
    "### SPARK submit "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8defa5bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Найден JDBC драйвер: /opt/workspace/jars/postgresql-42.6.2.jar\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "JAR_PATH = os.path.abspath(\"jars/postgresql-42.6.2.jar\")\n",
    "\n",
    "# Проверка наличия файла\n",
    "if not os.path.exists(JAR_PATH):\n",
    "    raise FileNotFoundError(f\"JDBC драйвер не найден: {JAR_PATH}\")\n",
    "\n",
    "print(f\"Найден JDBC драйвер: {JAR_PATH}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12f472c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/07/22 16:24:27 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-----------+----------+-------------+-------------+------------+-----------------+----------------+--------------------+---------+\n",
      "|client_id|  last_name|first_name|   patronymic|date_of_birth|passport_num|passport_valid_to|           phone|           create_dt|update_dt|\n",
      "+---------+-----------+----------+-------------+-------------+------------+-----------------+----------------+--------------------+---------+\n",
      "|     6948|   Сьестнов|    Сергей|Станиславович|   1973-04-05| 8732 868620|             null|+7 914 996-22-46|1900-01-01 00:00:...|     null|\n",
      "|     3603|     Очаков|    Матвей|     Иванович|   1996-03-05| 2885 305052|       2041-03-05|+7 974 791-86-56|1900-01-01 00:00:...|     null|\n",
      "|     4699|     Абазин|    Эльдар|Владиславович|   1972-12-18| 5100 810950|             null|+7 930 390-63-97|1900-01-01 00:00:...|     null|\n",
      "|     7486|    Итяйкин|    Роберт| Владимирович|   2002-06-13| 8095 866027|       2022-06-13|+7 913 443-96-80|1900-01-01 00:00:...|     null|\n",
      "|     9386|   Шкабкина|  Анжелика|     Ивановна|   1964-03-31| 5360 464827|             null|+7 954 947-82-68|1900-01-01 00:00:...|     null|\n",
      "|     7763|    Швыкова|    Инесса|   Робертовна|   1992-06-06| 2538 923225|       2037-06-06|+7 998 132-15-68|1900-01-01 00:00:...|     null|\n",
      "| VIP-6237|    Узенева|     Нелли|   Геворковна|   1999-03-04| 6510 927714|       2044-03-04|+7 965 317-46-87|1900-01-01 00:00:...|     null|\n",
      "|     4932|   Тщедушин| Владислав|     Павлович|   1983-02-06| 1988 613561|       2028-02-06|+7 949 229-36-79|1900-01-01 00:00:...|     null|\n",
      "|     1456| Сывороткин| Станислав|      Львович|   1998-04-08| 2284 919348|       2043-04-08|+7 955 261-24-77|1900-01-01 00:00:...|     null|\n",
      "|     7642|   Рубакова|    Оксана|    Давидовна|   1997-12-05| 3365 607538|       2042-12-05|+7 950 562-20-57|1900-01-01 00:00:...|     null|\n",
      "|     8808|    Андреев|    Эльдар|   Богданович|   1985-01-15| 6492 191174|       2030-01-15|+7 944 151-66-85|1900-01-01 00:00:...|     null|\n",
      "|     3779|     Пначин|      Яков|   Богданович|   1973-04-08| 3032 452883|             null|+7 974 261-98-59|1900-01-01 00:00:...|     null|\n",
      "|     9247|    Езопова|    Полина|   Евгеньевна|   1959-11-04| 7483 791097|             null|+7 950 958-38-29|1900-01-01 00:00:...|     null|\n",
      "|     7416|    Жгутова|Станислава|   Тиграновна|   1965-01-24| 1146 812704|             null|+7 926 288-89-91|1900-01-01 00:00:...|     null|\n",
      "|     4679|Лазутченков|    Даниил|   Евдокиевич|   1972-05-19| 5771 567535|             null|+7 910 653-83-33|1900-01-01 00:00:...|     null|\n",
      "| VIP-9807|      Ныров|     Рашид|    Андреевич|   1994-03-29| 1032 762143|       2039-03-29|+7 975 461-49-58|1900-01-01 00:00:...|     null|\n",
      "|     2948|    Мляхова|   Валерия| Всеволодовна|   1979-06-11| 1152 376417|       2024-06-11|+7 949 269-82-53|1900-01-01 00:00:...|     null|\n",
      "|     7812|      Ишеев|     Игорь|   Степанович|   1998-08-26| 5534 217181|       2043-08-26|+7 925 408-82-64|1900-01-01 00:00:...|     null|\n",
      "|     8006|     Убоков|    Феликс|   Степанович|   1966-09-16| 2994 122762|             null|+7 992 426-84-40|1900-01-01 00:00:...|     null|\n",
      "|     6069|     Иянова|      Элла|   Степановна|   1952-08-08| 3792 892752|             null|+7 933 623-61-65|1900-01-01 00:00:...|     null|\n",
      "+---------+-----------+----------+-------------+-------------+------------+-----------------+----------------+--------------------+---------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import Row\n",
    "import os\n",
    "\n",
    "JAR_PATH = os.path.abspath(\"jars/postgresql-42.6.2.jar\")\n",
    "\n",
    "spark = SparkSession.builder \\\n",
    "                .appName(\"PySpark App\") \\\n",
    "\t\t\t\t.enableHiveSupport() \\\n",
    "\t\t\t\t.config(\"spark.jars\", JAR_PATH) \\\n",
    "\t.getOrCreate()\n",
    "spark.sparkContext.setLogLevel(\"ERROR\")\n",
    "\n",
    "df = spark.read \\\n",
    "\t\t.format(\"jdbc\") \\\n",
    "\t\t.option(\"url\", \"jdbc:postgresql://...:.../edu\") \\\n",
    "\t\t.option(\"driver\", \"org.postgresql.Driver\") \\\n",
    "\t\t.option(\"dbtable\", \"bank.clients\") \\\n",
    "\t\t.option(\"user\", \"detn\") \\\n",
    "\t\t.option(\"password\", \"frodobaggins\") \\\n",
    "\t\t.load()\n",
    "\n",
    "df.write.mode(\"overwrite\").format(\"parquet\").saveAsTable(\"bank_clients\")\n",
    "df.show()\n",
    "spark.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
